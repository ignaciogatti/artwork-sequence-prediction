{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curatornet MAE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/root/work/datasets/artwork_sequence/'\n",
    "CONFIG_BASE_PATH = '/root/work/artwork_sequence/train_test_configuration'\n",
    "DATASET_PATH = '/root/work/datasets/'\n",
    "\n",
    "CURATORNET_CONFIG_PATH = os.path.join(CONFIG_BASE_PATH,'curatornet')\n",
    "CURATORNET_SEQUENCE_CONFIG_PATH = os.path.join(CONFIG_BASE_PATH,'curatornet_sequence')\n",
    "\n",
    "CURATORNET_DATA_PATH = os.path.join(DATASET_PATH,'curatornet_data')\n",
    "\n",
    "RESULT_PATH = '/root/work/artwork_sequence/predicted_tours'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "museum_sequence_path = {\n",
    "    'curatornet_code_train_matrix' : os.path.join(CONFIG_BASE_PATH, 'curatornet_code_train_matrix.npy'),\n",
    "    'curatornet_code_test_matrix' : os.path.join(CONFIG_BASE_PATH, 'curatornet_code_test_matrix.npy'),\n",
    "    \n",
    "    'curatornet_sequence_train_matrix' : os.path.join(CONFIG_BASE_PATH, 'curatornet_sequence_train_matrix.npy'),\n",
    "    'curatornet_sequence_test_matrix' : os.path.join(CONFIG_BASE_PATH, 'curatornet_sequence_test_matrix.npy'),\n",
    "    \n",
    "    'curatornet_purchase_data_train' : os.path.join(CURATORNET_DATA_PATH, 'curatornet_purchase_data_train.csv'),\n",
    "    'curatornet_purchase_data_test' : os.path.join(CURATORNET_DATA_PATH, 'curatornet_purchase_data_test.csv' ),\n",
    "    \n",
    "    'curatornet_sequence_purchase_data_train' : os.path.join(CURATORNET_DATA_PATH, 'curatornet_sequence_purchase_data_train.csv'),\n",
    "    'curatornet_sequence_purchase_data_test' : os.path.join(CURATORNET_DATA_PATH, 'curatornet_sequence_purchase_data_test.csv' )\n",
    "}\n",
    "museum_sequence_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_weights_path(CONFIG_PATH, window_size):\n",
    "    trained_weights_path = {\n",
    "            'weights_folder' : os.path.join(CONFIG_PATH, 'config_'+str(window_size)+'/trained_model_weights')\n",
    "        }\n",
    "\n",
    "    return trained_weights_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curatornet_purchase_data_train = pd.read_csv(museum_sequence_path['curatornet_purchase_data_train'])\n",
    "df_curatornet_purchase_data_test = pd.read_csv(museum_sequence_path['curatornet_purchase_data_test'])\n",
    "\n",
    "df_curatornet_sequence_data_train = pd.read_csv(museum_sequence_path['curatornet_sequence_purchase_data_train'])\n",
    "df_curatornet_sequence_data_test = pd.read_csv(museum_sequence_path['curatornet_sequence_purchase_data_test'])\n",
    "\n",
    "curatornet_code_train_matrix = np.load(museum_sequence_path['curatornet_code_train_matrix'])\n",
    "curatornet_code_test_matrix = np.load(museum_sequence_path['curatornet_code_test_matrix'])\n",
    "\n",
    "curatornet_sequence_train_matrix = np.load(museum_sequence_path['curatornet_sequence_train_matrix'])\n",
    "curatornet_sequence_test_matrix = np.load(museum_sequence_path['curatornet_sequence_test_matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_curatornet_purchase_data_train.shape)\n",
    "print(df_curatornet_purchase_data_test.shape)\n",
    "\n",
    "print(df_curatornet_sequence_data_train.shape)\n",
    "print(df_curatornet_sequence_data_test.shape)\n",
    "\n",
    "print(curatornet_code_train_matrix.shape)\n",
    "print(curatornet_code_test_matrix.shape)\n",
    "\n",
    "print(curatornet_sequence_train_matrix.shape)\n",
    "print(curatornet_sequence_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curatornet_user_purchases_data = {\n",
    "    'train_medatada': df_curatornet_purchase_data_train,\n",
    "    'test_medatada': df_curatornet_purchase_data_test,\n",
    "    \n",
    "    'matrix_train': curatornet_code_train_matrix,\n",
    "    'matrix_test' : curatornet_code_test_matrix\n",
    "}\n",
    "\n",
    "curatornet_sequence_data = {\n",
    "    \n",
    "    'train_medatada': df_curatornet_sequence_data_train,\n",
    "    'test_medatada': df_curatornet_sequence_data_test,\n",
    "    \n",
    "    'matrix_train': curatornet_sequence_train_matrix,\n",
    "    'matrix_test' : curatornet_sequence_test_matrix\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curator_config = curatornet_sequence_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sequence_prediction_factory import Sequence_prediction_multivariate, Sequence_prediction_univariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_train_matrix = curator_config['matrix_train']\n",
    "code_test_matrix = curator_config['matrix_test']\n",
    "\n",
    "df_train = curator_config['train_medatada']\n",
    "df_test = curator_config['test_medatada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_matrix = np.concatenate([code_train_matrix, code_test_matrix])\n",
    "all_data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata = pd.concat([df_train, df_test], ignore_index=True)\n",
    "all_metadata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define window size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "\n",
    "split_time = curatornet_code_train_matrix.shape[0]\n",
    "\n",
    "X = curatornet_code_test_matrix\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "#Number of artwork's feature\n",
    "n_features = X.shape[1]\n",
    "\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = curatornet_code_train_matrix.shape[0]\n",
    "model_prediction =Sequence_prediction_univariate(\n",
    "    X=X, \n",
    "    shuffle_buffer_size=shuffle_buffer_size, \n",
    "    split_time=split_time, \n",
    "    train_batch_size=batch_size, \n",
    "    val_batch_size=batch_size,\n",
    "    CONFIG_PATH=CURATORNET_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and define the RNN model \n",
    "model_prediction.set_window_size(window_size)\n",
    "model = model_prediction.get_model()\n",
    "model.define_model(conv_filter=20, lstm_filter=40, dense_filter=20, prediction_length=1)\n",
    "model.get_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look for previous user's purchases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_purchases_matrix(user_id, window_size, df, code_matrix):\n",
    "    \n",
    "    #Look for user's purchases\n",
    "    df_user_purchases = df[df['user_id_hash'] == user_id]\n",
    "    \n",
    "    previous_purchases = len(df_user_purchases)\n",
    "    \n",
    "    #More purchases than window size\n",
    "    if previous_purchases > window_size:\n",
    "        df_user_purchases = df_user_purchases.iloc[previous_purchases - window_size:]\n",
    "    \n",
    "    user_purchase_matrix = code_matrix[list(df_user_purchases.index),:]\n",
    "    \n",
    "    #Less purchases than window size\n",
    "    while user_purchase_matrix.shape[0] < window_size:\n",
    "        user_purchase_matrix = np.vstack([user_purchase_matrix, user_purchase_matrix[-1,:]])\n",
    "    \n",
    "    return user_purchase_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    if len(series.shape) == 1:\n",
    "            series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.map(lambda w: (w[:]))\n",
    "    ds = ds.batch(batch_size)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_evaluation():\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'feature' : [],\n",
    "            'forecast': [],\n",
    "            'x_valid':[],\n",
    "            'mae':[]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prediction(model_prediction, X, X_valid, window_size, batch_size, weights_path):\n",
    "    \n",
    "    #Get dataframe to save prediction\n",
    "    df_evaluation = get_dataframe_evaluation()\n",
    "    \n",
    "    model = model_prediction.get_model()\n",
    "    model.define_model(conv_filter=20, lstm_filter=40, dense_filter=20, prediction_length=1)\n",
    "\n",
    "    for feature in range(n_features):\n",
    "\n",
    "        #Load weights for feature i\n",
    "        model.set_index(feature)\n",
    "        model.load_weights(get_trained_weights_path(weights_path, window_size))\n",
    "\n",
    "        #Define feature to take into account for prediction\n",
    "        x_influence_features = model.get_indexes_features()\n",
    "        x_influence_features = np.insert(arr=x_influence_features, obj=0, values=int(feature))\n",
    "        x_feature = X[:,x_influence_features.astype(int)]\n",
    "\n",
    "        #Predict feature i\n",
    "        rnn_forecast = model_forecast(model.get_model(), x_feature, window_size, batch_size)\n",
    "        #print(rnn_forecast)\n",
    "        #Get validation dataset \n",
    "        x_valid = X_valid[0, feature]\n",
    "\n",
    "        #Compute MAE\n",
    "        mae = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy().mean()\n",
    "\n",
    "        df_evaluation = df_evaluation.append({\n",
    "            'feature' : feature,\n",
    "            'forecast': rnn_forecast[0][0],\n",
    "            'x_valid':x_valid,\n",
    "            'mae':mae\n",
    "                       }, \n",
    "                       ignore_index=True)\n",
    "\n",
    "    return df_evaluation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchases_prediction_dict = {}\n",
    "\n",
    "for index, row in df_curatornet_purchase_data_test.head().iterrows():\n",
    "    user_purchases_matrix = get_user_purchases_matrix(row['user_id_hash'], window_size, df_curatornet_purchase_data_test, curatornet_code_test_matrix)\n",
    "    \n",
    "    #Set seed\n",
    "    X = user_purchases_matrix\n",
    "    #Set x_valid\n",
    "    X_valid = code_test_matrix[index, :].reshape((1, -1))\n",
    "    \n",
    "    \n",
    "    #Compute evaluation\n",
    "    df_evaluation = get_user_prediction(model_prediction, X, X_valid, window_size, batch_size, CURATORNET_CONFIG_PATH)\n",
    "    \n",
    "    user_purchases_prediction_dict[row['user_id_hash']] = df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances,euclidean_distances\n",
    "\n",
    "for user_id, df_group in df_test.groupby('user_id_hash'):\n",
    "    print(user_id)\n",
    "    indexes = list(df_group.index)\n",
    "    #Set seed\n",
    "    X = code_test_matrix[indexes[-4:-1]]\n",
    "    print(X.shape)\n",
    "    X_valid = code_test_matrix[indexes[-1], :].reshape((1, -1))\n",
    "    \n",
    "    #Compute evaluation\n",
    "    df_evaluation = get_user_prediction(model_prediction, X, X_valid, window_size, batch_size, CURATORNET_SEQUENCE_CONFIG_PATH)\n",
    "    \n",
    "    forescast = df_evaluation['forecast']\n",
    "    feature_list = list(forescast.values)\n",
    "    forecast_matrix = np.stack(feature_list)\n",
    "    forecast_matrix = forecast_matrix.T\n",
    "    \n",
    "    sim_matrix = cosine_similarity(forecast_matrix.reshape((1, -1)), X_valid.reshape((1, -1)))\n",
    "    print(sim_matrix)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation['mae'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct predicted code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forescast = df_evaluation['forecast']\n",
    "forescast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(forescast.values)\n",
    "forecast_matrix = np.stack(feature_list)\n",
    "forecast_matrix = forecast_matrix.T\n",
    "forecast_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances,euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cosine similarity\n",
    "sim_matrix = cosine_similarity(forecast_matrix.reshape((1, -1)), curatornet_code_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_index = np.argsort(sim_matrix.reshape((-1,)))\n",
    "sort_index[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix[0][sort_index[-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
