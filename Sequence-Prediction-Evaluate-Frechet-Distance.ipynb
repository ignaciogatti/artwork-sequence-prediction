{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artwork Sequence Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from multivariate_fretech_distance import frechet_distance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration/multivariate'\n",
    "#CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration/univariate'\n",
    "\n",
    "BASE_PATH = '/root/work/artwork_sequence/kfold'\n",
    "folder ='folder_3'\n",
    "\n",
    "DATASET_PATH = os.path.join(BASE_PATH, folder)\n",
    "\n",
    "CONFIG_PATH = os.path.join(BASE_PATH,'univariate')\n",
    "\n",
    "CONFIG_PATH = os.path.join(CONFIG_PATH,folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_index = 4\n",
    "\n",
    "museum_sequence_path = {\n",
    "    'x_train' : os.path.join(DATASET_PATH, 'X_train.csv'),\n",
    "    'x_test' : os.path.join(DATASET_PATH, 'X_test.csv'),\n",
    "    'x_train_matrix' : os.path.join(DATASET_PATH, 'X_train_matrix.npy'),\n",
    "    'x_test_matrix' : os.path.join(DATASET_PATH, 'X_test_matrix.npy'),\n",
    "    'weights_folder' : os.path.join(CONFIG_PATH, 'config_'+str(window_index)+'/trained_model_weights')\n",
    "}\n",
    "museum_sequence_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.read_csv(museum_sequence_path['x_train'], index_col=0)\n",
    "df_x_test = pd.read_csv(museum_sequence_path['x_test'], index_col=0)\n",
    "x_train_matrix = np.load(museum_sequence_path['x_train_matrix'])\n",
    "x_test_matrix = np.load(museum_sequence_path['x_test_matrix'])\n",
    "df_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config  data to fit with the model input\n",
    "\n",
    "Because the **Prediction feature model** split the data into training and validation dataset, it is necessary to give all the data in only one block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define timeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = np.arange(x_train_matrix.shape[0] + x_test_matrix.shape[0])\n",
    "timeline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define configuration to deal with the windowed dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = x_train_matrix.shape[0]\n",
    "\n",
    "X = np.concatenate((x_train_matrix, x_test_matrix))\n",
    "\n",
    "window_size = window_index\n",
    "\n",
    "#Number of artwork's feature\n",
    "n_features = X.shape[1]\n",
    "\n",
    "#Number of feature to take into account\n",
    "n_influence_features=5\n",
    "\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sequence_prediction_factory import Sequence_prediction_multivariate, Sequence_prediction_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_univariate = Sequence_prediction_univariate(\n",
    "    X=X, \n",
    "    shuffle_buffer_size=shuffle_buffer_size, \n",
    "    split_time=split_time, \n",
    "    train_batch_size=batch_size, \n",
    "    val_batch_size=batch_size,\n",
    "    CONFIG_PATH=CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model_multivariate = Sequence_prediction_multivariate(\n",
    "    X=X, \n",
    "    shuffle_buffer_size=shuffle_buffer_size, \n",
    "    split_time=split_time, \n",
    "    train_batch_size=batch_size, \n",
    "    val_batch_size=batch_size, \n",
    "    window_size=window_size, \n",
    "    n_influence_features=n_influence_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = model_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "#Get and define the RNN model \n",
    "model_prediction.set_window_size(window_size)\n",
    "model = model_prediction.get_model()\n",
    "model.define_model(conv_filter=20, lstm_filter=40, dense_filter=20, prediction_length=1)\n",
    "model.get_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_plot import plot_series, plot_train_history, plot_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    if len(series.shape) == 1:\n",
    "            series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.map(lambda w: (w[:]))\n",
    "    ds = ds.batch(batch_size)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.DataFrame({'feature' : [],\n",
    "                             'forecast': [],\n",
    "                             'x_valid':[],\n",
    "                             'mae':[]})\n",
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in range(n_features):\n",
    "    \n",
    "    #Load weights for feature i\n",
    "    model.set_index(feature)\n",
    "    model.load_weights(museum_sequence_path)\n",
    "    \n",
    "    #Define feature to take into account for prediction\n",
    "    x_influence_features = model.get_indexes_features()\n",
    "    x_influence_features = np.insert(arr=x_influence_features, obj=0, values=int(feature))\n",
    "    x_feature = X[:,x_influence_features.astype(int)]\n",
    "    \n",
    "    #Predict feature i\n",
    "    rnn_forecast = model_forecast(model.get_model(), x_feature, window_size, batch_size)\n",
    "    rnn_forecast = rnn_forecast[split_time-window_size+1:,-1]\n",
    "\n",
    "    #Get validation dataset \n",
    "    x_valid = x_feature[split_time:, 0]\n",
    "\n",
    "    #Compute MAE\n",
    "    mae = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy().mean()\n",
    "\n",
    "    df_evaluation = df_evaluation.append({'feature' : feature,\n",
    "                    'forecast': rnn_forecast,\n",
    "                    'x_valid':x_valid,\n",
    "                    'mae':mae\n",
    "                   }, \n",
    "                   ignore_index=True)\n",
    "\n",
    "df_evaluation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to compute Frenchet distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the values for real and predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_feature_matrix = np.vstack(list(df_evaluation['forecast'])).T\n",
    "real_feature_matrix = np.vstack(list(df_evaluation['x_valid'])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compute mean and covariaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_forecast_feature = np.mean(forecast_feature_matrix, axis=0)\n",
    "sigma_forecast_feature = np.cov(forescast_feature_matrix, rowvar=False)\n",
    "\n",
    "mu_real_feature = np.mean(real_feature_matrix, axis=0)\n",
    "sigma_real_feature = np.cov(real_feature_matrix, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we visualize what the pairwise multivariate distributions of the inception features look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [2, 4, 5]\n",
    "forecast_dist = np.random.multivariate_normal(mu_forecast_feature[indices], sigma_forecast_feature[indices][:, indices], 1000)\n",
    "real_dist = np.random.multivariate_normal(mu_real_feature[indices], sigma_real_feature[indices][:, indices], 1000)\n",
    "\n",
    "df_forecast = pd.DataFrame(forecast_dist, columns=indices)\n",
    "df_real = pd.DataFrame(real_dist, columns=indices)\n",
    "df_forecast[\"is_real\"] = \"no\"\n",
    "df_real[\"is_real\"] = \"yes\"\n",
    "df = pd.concat([df_forecast, df_real])\n",
    "sns.pairplot(df, plot_kws={'alpha': 0.1}, hue='is_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frechet_distance(mu_x=mu_forecast_feature,mu_y=mu_real_feature,sigma_x=sigma_forecast_feature,sigma_y=sigma_real_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
