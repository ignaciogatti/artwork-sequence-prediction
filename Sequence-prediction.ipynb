{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artwork sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration/multivariate'\n",
    "#CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration/univariate'\n",
    "CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights_folder': '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple/config_3/trained_model_weights',\n",
       " 'x_test': '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple/X_test.csv',\n",
       " 'x_test_matrix': '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple/X_test_matrix.npy',\n",
       " 'x_train': '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple/X_train.csv',\n",
       " 'x_train_matrix': '/root/work/artwork_sequence/train_test_configuration/univariate_predict_multiple/X_train_matrix.npy'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_index = 3\n",
    "\n",
    "museum_sequence_path = {\n",
    "    'x_train' : os.path.join(CONFIG_PATH, 'X_train.csv'),\n",
    "    'x_test' : os.path.join(CONFIG_PATH, 'X_test.csv'),\n",
    "    'x_train_matrix' : os.path.join(CONFIG_PATH, 'X_train_matrix.npy'),\n",
    "    'x_test_matrix' : os.path.join(CONFIG_PATH, 'X_test_matrix.npy'),\n",
    "    'weights_folder' : os.path.join(CONFIG_PATH, 'config_'+str(window_index)+'/trained_model_weights')\n",
    "}\n",
    "museum_sequence_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/prado_cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/prado_cra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tour_path\n",
       "20  /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "7   /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "40  /root/work/datasets/artwork_sequence/prado_cra...\n",
       "0   /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "23  /root/work/datasets/artwork_sequence/prado_cra..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train = pd.read_csv(museum_sequence_path['x_train'], index_col=0)\n",
    "df_x_test = pd.read_csv(museum_sequence_path['x_test'], index_col=0)\n",
    "x_train_matrix = np.load(museum_sequence_path['x_train_matrix'])\n",
    "x_test_matrix = np.load(museum_sequence_path['x_test_matrix'])\n",
    "df_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config data to fit with the model input\n",
    "\n",
    "Because the **Prediction feature model** split the data into training and validation dataset, it is necessary to give all the data in only one block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define timeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = np.arange(x_train_matrix.shape[0] + x_test_matrix.shape[0])\n",
    "time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define configuration to deal with the windowed dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = x_train_matrix.shape[0]\n",
    "\n",
    "X = np.concatenate((x_train_matrix, x_test_matrix))\n",
    "\n",
    "#length of the history\n",
    "window_size = window_index\n",
    "\n",
    "#Number of artwork's feature\n",
    "n_features = X.shape[1]\n",
    "\n",
    "#Number of feature to take into account\n",
    "n_influence_features=10\n",
    "\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sequence_prediction_factory import Sequence_prediction_multivariate, Sequence_prediction_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_univariate = Sequence_prediction_univariate(\n",
    "    X=X, \n",
    "    shuffle_buffer_size=shuffle_buffer_size, \n",
    "    split_time=split_time, \n",
    "    train_batch_size=batch_size, \n",
    "    val_batch_size=batch_size, \n",
    "    window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multivariate = Sequence_prediction_multivariate(\n",
    "    X=X, \n",
    "    shuffle_buffer_size=shuffle_buffer_size, \n",
    "    split_time=split_time, \n",
    "    train_batch_size=batch_size, \n",
    "    val_batch_size=batch_size, \n",
    "    window_size=window_size, \n",
    "    n_influence_features=n_influence_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = model_univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Feature 299 -------------\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f0abafa7840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0abafa7840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f0abafa7840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0abafa7840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f0abafa78c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0abafa78c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f0abafa78c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0abafa78c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f0abafa7840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0abafa7840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f0abafa7840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f0abafa7840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f0abafa78c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0abafa78c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f0abafa78c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f0abafa78c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1573 - mae: 1.5329 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.8817 - mae: 1.2262 - val_loss: 0.9360 - val_mae: 1.2873\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6423 - mae: 0.9903 - val_loss: 0.7193 - val_mae: 1.0852\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5169 - mae: 0.8698 - val_loss: 0.6005 - val_mae: 0.9684\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4501 - mae: 0.7975 - val_loss: 0.5268 - val_mae: 0.8817\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3947 - mae: 0.7292 - val_loss: 0.4686 - val_mae: 0.8130\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3423 - mae: 0.6666 - val_loss: 0.4208 - val_mae: 0.7554\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2986 - mae: 0.6129 - val_loss: 0.3867 - val_mae: 0.7120\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.2699 - mae: 0.5776 - val_loss: 0.3638 - val_mae: 0.6843\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2521 - mae: 0.5596 - val_loss: 0.3471 - val_mae: 0.6680\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2396 - mae: 0.5481 - val_loss: 0.3320 - val_mae: 0.6524\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.2291 - mae: 0.5376 - val_loss: 0.3184 - val_mae: 0.6380\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2200 - mae: 0.5284 - val_loss: 0.3065 - val_mae: 0.6253\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2126 - mae: 0.5208 - val_loss: 0.2968 - val_mae: 0.6146\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.2069 - mae: 0.5148 - val_loss: 0.2889 - val_mae: 0.6059\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2024 - mae: 0.5102 - val_loss: 0.2825 - val_mae: 0.5991\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.1987 - mae: 0.5066 - val_loss: 0.2772 - val_mae: 0.5934\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.1955 - mae: 0.5035 - val_loss: 0.2727 - val_mae: 0.5887\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.1928 - mae: 0.5009 - val_loss: 0.2689 - val_mae: 0.5848\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.1905 - mae: 0.4987 - val_loss: 0.2655 - val_mae: 0.5814\n",
      "--- 3708.4098756313324 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "models = []\n",
    "start_time = time.time()\n",
    "for i in range(n_features):\n",
    "    clear_output(wait=True)\n",
    "    print(\"---------- Feature %s -------------\" % (i))\n",
    "    \n",
    "    model_prediction.set_index(i)\n",
    "    model = model_prediction.get_model()\n",
    "    model.define_model(conv_filter=16, lstm_filter=32, dense_filter=16, prediction_length=10)\n",
    "    model.train_model(epochs=20, lr=1e-6)\n",
    "    models.append(model)\n",
    "    \n",
    "    #Save weights\n",
    "    model.save_weights(museum_sequence_path)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Prediction_model_feature' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b91bb590fb5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Prediction_model_feature' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "models[0].model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
