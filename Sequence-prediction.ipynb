{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artwork sequence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>style</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>artist</th>\n",
       "      <th>imageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44196.jpg</td>\n",
       "      <td>La Hacienda Buenavista en Ponce, Puerto Rico</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>landscape</td>\n",
       "      <td>1840</td>\n",
       "      <td>francisco oller</td>\n",
       "      <td>https://uploads8.wikiart.org/images/francisco-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50608.jpg</td>\n",
       "      <td>Woman and Child on a Bridge</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>genre painting</td>\n",
       "      <td>1848</td>\n",
       "      <td>honore daumier</td>\n",
       "      <td>https://uploads4.wikiart.org/images/honore-dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27526.jpg</td>\n",
       "      <td>On the Shore</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>genre painting</td>\n",
       "      <td>1853</td>\n",
       "      <td>honore daumier</td>\n",
       "      <td>https://uploads7.wikiart.org/images/honore-dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102063.jpg</td>\n",
       "      <td>Bathers</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>genre painting</td>\n",
       "      <td>1853</td>\n",
       "      <td>honore daumier</td>\n",
       "      <td>https://uploads4.wikiart.org/images/honore-dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66688.jpg</td>\n",
       "      <td>Study for the Self Portrait</td>\n",
       "      <td>Impressionism</td>\n",
       "      <td>self-portrait</td>\n",
       "      <td>1855</td>\n",
       "      <td>edgar degas</td>\n",
       "      <td>https://uploads6.wikiart.org/images/edgar-dega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                         title          style  \\\n",
       "0   44196.jpg  La Hacienda Buenavista en Ponce, Puerto Rico  Impressionism   \n",
       "1   50608.jpg                   Woman and Child on a Bridge  Impressionism   \n",
       "2   27526.jpg                                  On the Shore  Impressionism   \n",
       "3  102063.jpg                                       Bathers  Impressionism   \n",
       "4   66688.jpg                   Study for the Self Portrait  Impressionism   \n",
       "\n",
       "            genre  date           artist  \\\n",
       "0       landscape  1840  francisco oller   \n",
       "1  genre painting  1848   honore daumier   \n",
       "2  genre painting  1853   honore daumier   \n",
       "3  genre painting  1853   honore daumier   \n",
       "4   self-portrait  1855      edgar degas   \n",
       "\n",
       "                                            imageUrl  \n",
       "0  https://uploads8.wikiart.org/images/francisco-...  \n",
       "1  https://uploads4.wikiart.org/images/honore-dau...  \n",
       "2  https://uploads7.wikiart.org/images/honore-dau...  \n",
       "3  https://uploads4.wikiart.org/images/honore-dau...  \n",
       "4  https://uploads6.wikiart.org/images/edgar-dega...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df_impressionist_sorted = pd.read_csv('impressionsist_sorted.csv')\n",
    "impressionist_sorted_matrix = np.load('impressionist_sorted_matrix.npy')\n",
    "df_impressionist_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(impressionist_sorted_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = 4500\n",
    "\n",
    "time_train = time[:split_time]\n",
    "time_valid = time[split_time:]\n",
    "\n",
    "X = impressionist_sorted_matrix\n",
    "\n",
    "window_size = 20\n",
    "batch_size = 256\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prediction_model_feature import Prediction_model_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Feature 33 -------------\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fc61ed6e950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fc61ed6e950>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fc61ed6e950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fc61ed6e950>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fc61ed6e9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fc61ed6e9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fc61ed6e9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fc61ed6e9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7fc61ed6e950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fc61ed6e950>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7fc61ed6e950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7fc61ed6e950>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7fc61ed6e9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fc61ed6e9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7fc61ed6e9d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7fc61ed6e9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Epoch 1/20\n",
      "18/18 [==============================] - 7s 372ms/step - loss: 1.8105 - mae: 2.2765 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.4784 - mae: 0.8532 - val_loss: 0.3597 - val_mae: 0.7121\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 2s 86ms/step - loss: 0.3279 - mae: 0.6608 - val_loss: 0.2665 - val_mae: 0.5863\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 2s 89ms/step - loss: 0.2754 - mae: 0.5870 - val_loss: 0.2358 - val_mae: 0.5463\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.2498 - mae: 0.5540 - val_loss: 0.2186 - val_mae: 0.5214\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 2s 87ms/step - loss: 0.2350 - mae: 0.5336 - val_loss: 0.2072 - val_mae: 0.5038\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.2246 - mae: 0.5191 - val_loss: 0.1988 - val_mae: 0.4922\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.2161 - mae: 0.5072 - val_loss: 0.1921 - val_mae: 0.4836\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 2s 90ms/step - loss: 0.2086 - mae: 0.4966 - val_loss: 0.1862 - val_mae: 0.4761\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 2s 88ms/step - loss: 0.2018 - mae: 0.4865 - val_loss: 0.1810 - val_mae: 0.4689\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(n_features):\n",
    "    clear_output(wait=True)\n",
    "    print(\"---------- Feature %s -------------\" % (i))\n",
    "    model_prediction = Prediction_model_feature(\n",
    "        X=X[:, i],\n",
    "        split_time=split_time,\n",
    "        train_batch_size=batch_size, \n",
    "        val_batch_size=batch_size, \n",
    "        window_size=window_size, \n",
    "        shuffle_buffer=shuffle_buffer_size,\n",
    "        name=\"feature \" + str(i))\n",
    "    model_prediction.define_model()\n",
    "    model_prediction.train_model(epochs=20, lr=1e-6)\n",
    "    models.append(model_prediction)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = load_model('wasserstein_decoder.h5')\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test decoder with example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = decoder_model.predict(x_train[1].reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(p[0][...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sliced validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_dataset(series, window_size, batch_size):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i in range(n_features):\n",
    "    val_dataset = validation_dataset(x_valid[:,i], window_size, batch_size)\n",
    "    for x, y in val_dataset.take(1):\n",
    "        prediction_feature = models[i].model.predict(x)[0]\n",
    "        prediction.append(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for p in prediction:\n",
    "    code.append(prediction[0][0])\n",
    "\n",
    "code = np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decode code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = decoder_model.predict(code.reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_decode = decoder_model.predict(x_valid[0].reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valid_decode[0][...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "\n",
    "cosine_distances(code, x_valid[0][...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feature prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_plot import plot_series, plot_train_history, plot_prediction\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = validation_dataset(x_valid[:,0], window_size, batch_size)\n",
    "for x, y in val_dataset.take(1):\n",
    "    prediction = models[0].model.predict(x)[0]\n",
    "    plot = plot_prediction([x[0].numpy(), y[0].numpy(), prediction[0]] , 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = validation_dataset(x_valid[:,20], window_size, batch_size)\n",
    "for x, y in val_dataset.take(1):\n",
    "    prediction = models[20].model.predict(x)[0]\n",
    "    plot = plot_prediction([x[0].numpy(), y[0].numpy(), prediction[0]] , 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict x_valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_train[:, 1], x_valid[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forecast = model_forecast(model_prediction.model, x, window_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forecast = rnn_forecast[split_time-window_size+1:,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time_valid, [rnn_forecast], label=\"rnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
