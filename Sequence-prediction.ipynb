{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artwork sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '/root/work/artwork_sequence/train_test_configuration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights_folder': '/root/work/artwork_sequence/train_test_configuration/config_0/trained_model_weights',\n",
       " 'x_test': '/root/work/artwork_sequence/train_test_configuration/config_0/X_test.csv',\n",
       " 'x_test_matrix': '/root/work/artwork_sequence/train_test_configuration/config_0/X_test_matrix.npy',\n",
       " 'x_train': '/root/work/artwork_sequence/train_test_configuration/config_0/X_train.csv',\n",
       " 'x_train_matrix': '/root/work/artwork_sequence/train_test_configuration/config_0/X_train_matrix.npy'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "museum_sequence_path = {\n",
    "    'x_train' : os.path.join(CONFIG_PATH, 'config_0/X_train.csv'),\n",
    "    'x_test' : os.path.join(CONFIG_PATH, 'config_0/X_test.csv'),\n",
    "    'x_train_matrix' : os.path.join(CONFIG_PATH, 'config_0/X_train_matrix.npy'),\n",
    "    'x_test_matrix' : os.path.join(CONFIG_PATH, 'config_0/X_test_matrix.npy'),\n",
    "    'weights_folder' : os.path.join(CONFIG_PATH, 'config_0/trained_model_weights')\n",
    "}\n",
    "museum_sequence_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tour_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/prado_cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/rijksmuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/root/work/datasets/artwork_sequence/prado_cra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tour_path\n",
       "20  /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "7   /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "40  /root/work/datasets/artwork_sequence/prado_cra...\n",
       "0   /root/work/datasets/artwork_sequence/rijksmuse...\n",
       "23  /root/work/datasets/artwork_sequence/prado_cra..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train = pd.read_csv(museum_sequence_path['x_train'], index_col=0)\n",
    "df_x_test = pd.read_csv(museum_sequence_path['x_test'], index_col=0)\n",
    "x_train_matrix = np.load(museum_sequence_path['x_train_matrix'])\n",
    "x_test_matrix = np.load(museum_sequence_path['x_test_matrix'])\n",
    "df_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config data to fit with the model input\n",
    "\n",
    "Because the **Prediction feature model** split the data into training and validation dataset, it is necessary to give all the data in only one block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define timeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = np.arange(x_train_matrix.shape[0] + x_test_matrix.shape[0])\n",
    "time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define configuration to deal with the windowed dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = x_train_matrix.shape[0]\n",
    "\n",
    "X = np.concatenate((x_train_matrix, x_test_matrix))\n",
    "\n",
    "#the length mean average of the tours\n",
    "window_size = 5\n",
    "\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function to save model's weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(model, index, museum_sequence_path):\n",
    "    #Create the folder where the weights are saved\n",
    "    model_feature_folder = os.path.join(museum_sequence_path['weights_folder'], 'model_feature_'+str(index))\n",
    "    if not os.path.exists(model_feature_folder):\n",
    "        os.makedirs(model_feature_folder)\n",
    "    \n",
    "    #Save weights\n",
    "    model.save_weights(os.path.join(model_feature_folder, 'weights_feature_'+str(index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prediction_model_feature import Prediction_model_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Feature 0 -------------\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f556f0e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f556f0e8840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f556f0e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f556f0e8840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f556f0e88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f556f0e88c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f556f0e88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f556f0e88c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f556f0e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f556f0e8840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f556f0e8840> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f556f0e8840>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f556f0e88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f556f0e88c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f556f0e88c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f556f0e88c8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "5/5 [==============================] - 5s 1s/step - loss: 5.9086 - mae: 6.3998 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2.5015 - mae: 2.9665 - val_loss: 1.6763 - val_mae: 2.1579\n",
      "Epoch 3/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.3195 - mae: 1.7671 - val_loss: 0.6628 - val_mae: 1.0846\n",
      "Epoch 4/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.8607 - mae: 1.2635 - val_loss: 0.6282 - val_mae: 1.0313\n",
      "Epoch 5/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6645 - mae: 1.0614 - val_loss: 0.6711 - val_mae: 1.0979\n",
      "Epoch 6/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5959 - mae: 1.0001 - val_loss: 0.4876 - val_mae: 0.8912\n",
      "Epoch 7/40\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.5195 - mae: 0.9064 - val_loss: 0.4661 - val_mae: 0.8582\n",
      "Epoch 8/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4911 - mae: 0.8785 - val_loss: 0.4932 - val_mae: 0.9026\n",
      "Epoch 9/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4605 - mae: 0.8496 - val_loss: 0.4307 - val_mae: 0.8282\n",
      "Epoch 10/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4378 - mae: 0.8208 - val_loss: 0.4090 - val_mae: 0.8007\n",
      "Epoch 11/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4244 - mae: 0.8074 - val_loss: 0.4167 - val_mae: 0.8141\n",
      "Epoch 12/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4050 - mae: 0.7891 - val_loss: 0.3837 - val_mae: 0.7760\n",
      "Epoch 13/40\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3941 - mae: 0.7774 - val_loss: 0.3703 - val_mae: 0.7611\n",
      "Epoch 14/40\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3843 - mae: 0.7675 - val_loss: 0.3696 - val_mae: 0.7624\n",
      "Epoch 15/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3731 - mae: 0.7583 - val_loss: 0.3540 - val_mae: 0.7447\n",
      "Epoch 16/40\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3685 - mae: 0.7530 - val_loss: 0.3507 - val_mae: 0.7422\n",
      "Epoch 17/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3635 - mae: 0.7487 - val_loss: 0.3492 - val_mae: 0.7413\n",
      "Epoch 18/40\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3598 - mae: 0.7452 - val_loss: 0.3442 - val_mae: 0.7353\n",
      "Epoch 19/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3587 - mae: 0.7433 - val_loss: 0.3450 - val_mae: 0.7367\n",
      "Epoch 20/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3568 - mae: 0.7417 - val_loss: 0.3433 - val_mae: 0.7348\n",
      "Epoch 21/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3558 - mae: 0.7405 - val_loss: 0.3420 - val_mae: 0.7331\n",
      "Epoch 22/40\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3551 - mae: 0.7396 - val_loss: 0.3422 - val_mae: 0.7337\n",
      "Epoch 23/40\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3539 - mae: 0.7387 - val_loss: 0.3408 - val_mae: 0.7319\n",
      "Epoch 24/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3532 - mae: 0.7378 - val_loss: 0.3404 - val_mae: 0.7316\n",
      "Epoch 25/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3524 - mae: 0.7369 - val_loss: 0.3400 - val_mae: 0.7313\n",
      "Epoch 26/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3516 - mae: 0.7360 - val_loss: 0.3392 - val_mae: 0.7303\n",
      "Epoch 27/40\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3510 - mae: 0.7353 - val_loss: 0.3390 - val_mae: 0.7302\n",
      "Epoch 28/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3503 - mae: 0.7347 - val_loss: 0.3385 - val_mae: 0.7296\n",
      "Epoch 29/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3498 - mae: 0.7341 - val_loss: 0.3381 - val_mae: 0.7291\n",
      "Epoch 30/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3493 - mae: 0.7336 - val_loss: 0.3379 - val_mae: 0.7289\n",
      "Epoch 31/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3488 - mae: 0.7331 - val_loss: 0.3375 - val_mae: 0.7284\n",
      "Epoch 32/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3484 - mae: 0.7326 - val_loss: 0.3373 - val_mae: 0.7282\n",
      "Epoch 33/40\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3479 - mae: 0.7320 - val_loss: 0.3371 - val_mae: 0.7279\n",
      "Epoch 34/40\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3475 - mae: 0.7315 - val_loss: 0.3368 - val_mae: 0.7275\n",
      "Epoch 35/40\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3471 - mae: 0.7311 - val_loss: 0.3366 - val_mae: 0.7273\n",
      "Epoch 36/40\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3466 - mae: 0.7306 - val_loss: 0.3364 - val_mae: 0.7271\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3462 - mae: 0.7301 - val_loss: 0.3362 - val_mae: 0.7268\n",
      "Epoch 38/40\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3459 - mae: 0.7298 - val_loss: 0.3360 - val_mae: 0.7267\n",
      "Epoch 39/40\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3455 - mae: 0.7294 - val_loss: 0.3359 - val_mae: 0.7265\n",
      "Epoch 40/40\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3452 - mae: 0.7291 - val_loss: 0.3358 - val_mae: 0.7263\n",
      "--- 15.438527345657349 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(n_features):\n",
    "    clear_output(wait=True)\n",
    "    print(\"---------- Feature %s -------------\" % (i))\n",
    "    model_prediction = Prediction_model_feature(\n",
    "        X=X[:, i],\n",
    "        split_time=split_time,\n",
    "        train_batch_size=batch_size, \n",
    "        val_batch_size=batch_size, \n",
    "        window_size=window_size, \n",
    "        shuffle_buffer=shuffle_buffer_size,\n",
    "        name=\"feature \" + str(i))\n",
    "    model_prediction.define_model()\n",
    "    model_prediction.train_model(epochs=40, lr=1e-6)\n",
    "    models.append(model_prediction)\n",
    "    \n",
    "    #Save weights\n",
    "    save_weights(model_prediction.get_model(), i, museum_sequence_path)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = load_model('wasserstein_decoder.h5')\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test decoder with example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = decoder_model.predict(X[1].reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(p[0][...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sliced validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_dataset(series, window_size, batch_size):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for i in range(n_features):\n",
    "    val_dataset = validation_dataset(x_valid[:,i], window_size, batch_size)\n",
    "    for x, y in val_dataset.take(1):\n",
    "        prediction_feature = models[i].model.predict(x)[0]\n",
    "        prediction.append(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for p in prediction:\n",
    "    code.append(prediction[0][0])\n",
    "\n",
    "code = np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decode code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = decoder_model.predict(code.reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_decode = decoder_model.predict(x_valid[0].reshape((1,1,1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valid_decode[0][...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "\n",
    "cosine_distances(code, x_valid[0][...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feature prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_plot import plot_series, plot_train_history, plot_prediction\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = validation_dataset(x_valid[:,0], window_size, batch_size)\n",
    "for x, y in val_dataset.take(1):\n",
    "    prediction = models[0].model.predict(x)[0]\n",
    "    plot = plot_prediction([x[0].numpy(), y[0].numpy(), prediction[0]] , 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = validation_dataset(x_valid[:,20], window_size, batch_size)\n",
    "for x, y in val_dataset.take(1):\n",
    "    prediction = models[20].model.predict(x)[0]\n",
    "    plot = plot_prediction([x[0].numpy(), y[0].numpy(), prediction[0]] , 'Simple LSTM model')\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict x_valid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "    ds = ds.batch(batch_size).prefetch(1)\n",
    "    forecast = model.predict(ds)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((x_train[:, 1], x_valid[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forecast = model_forecast(model_prediction.model, x, window_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_forecast = rnn_forecast[split_time-window_size+1:,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time_valid, [rnn_forecast], label=\"rnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
